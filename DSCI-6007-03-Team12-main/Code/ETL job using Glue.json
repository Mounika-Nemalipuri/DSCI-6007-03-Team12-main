{
	"jobConfig": {
		"name": "FInal Join job",
		"description": "",
		"role": "arn:aws:iam::992382814705:role/LabRole",
		"command": "glueetl",
		"version": "4.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "FInal Join job.py",
		"scriptLocation": "s3://aws-glue-assets-992382814705-us-east-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2024-04-19T12:38:19.168Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-992382814705-us-east-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": false,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-992382814705-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"sourceControlDetails": {
			"Provider": "GITHUB",
			"Repository": "",
			"Branch": ""
		}
	},
	"hasBeenSaved": false,
	"script": "import sys\r\nfrom awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\n\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\njob = Job(glueContext)\r\njob.init(args['JOB_NAME'], args)\r\n\r\n# Script generated for node patient_data\r\npatient_data_node1713529687845 = glueContext.create_dynamic_frame.from_catalog(database=\"project\", table_name=\"patient_data_csv\", transformation_ctx=\"patient_data_node1713529687845\")\r\n\r\n# Script generated for node patient_report\r\npatient_report_node1713529689005 = glueContext.create_dynamic_frame.from_catalog(database=\"project\", table_name=\"patient_report_csv\", transformation_ctx=\"patient_report_node1713529689005\")\r\n\r\n# Script generated for node iot_data\r\niot_data_node1713529690097 = glueContext.create_dynamic_frame.from_catalog(database=\"project\", table_name=\"iot_data1713527763947_csv\", transformation_ctx=\"iot_data_node1713529690097\")\r\n\r\n# Script generated for node patient_feedback\r\npatient_feedback_node1713529691376 = glueContext.create_dynamic_frame.from_catalog(database=\"project\", table_name=\"patient_feedback_data_csv\", transformation_ctx=\"patient_feedback_node1713529691376\")\r\n\r\n# Script generated for node Join\r\nJoin_node1713529821292 = Join.apply(frame1=patient_data_node1713529687845, frame2=patient_report_node1713529689005, keys1=[\"patient_id\"], keys2=[\"patient_id\"], transformation_ctx=\"Join_node1713529821292\")\r\n\r\n# Script generated for node Join1\r\nJoin1_node1713529874169 = Join.apply(frame1=patient_feedback_node1713529691376, frame2=iot_data_node1713529690097, keys1=[\"username\"], keys2=[\"patient_id\"], transformation_ctx=\"Join1_node1713529874169\")\r\n\r\n# Script generated for node Join\r\nJoin_node1713529922429 = Join.apply(frame1=Join1_node1713529874169, frame2=Join_node1713529821292, keys1=[\"patient_id\"], keys2=[\"patient_id\"], transformation_ctx=\"Join_node1713529922429\")\r\n\r\n# Convert DynamicFrame to PySpark DataFrame\r\ndata_frame = Join_node1713529922429.toDF()\r\n\r\n# Remove duplicates from the DataFrame based on 'patient_id'\r\ndeduplicated_df = data_frame.dropDuplicates(['patient_id'])\r\n\r\n# Write data frame to CSV format\r\ndeduplicated_df.coalesce(1).write.csv(\"s3://waste1/output1/finalfile.csv\", mode=\"overwrite\", header=True)\r\njob.commit()\r\n"
}